<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>STA410 Statistical Computation</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/yeti.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="site_libs/anchor-sections-1.0/anchor-sections.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 45px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h2 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h3 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h4 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h5 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h6 {
  padding-top: 50px;
  margin-top: -50px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Michelle Chan</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-book"></span>
     
    Coursework
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="coursework.html">
        <span class="fa fa-list"></span>
         
        Coursework Summary
      </a>
    </li>
    <li>
      <a href="STA410.html">
        <span class="fa fa-code"></span>
         
        STA410 Statistical Computation
      </a>
    </li>
    <li>
      <a href="STA457.html">
        <span class="fa fa-code"></span>
         
        STA457 Time Series Analysis
      </a>
    </li>
    <li>
      <a href="STA355.html">
        <span class="fa fa-code"></span>
         
        STA355 Theory of Statistical Practice
      </a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-cogs"></span>
     
    Student Research
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="STA490research1.html">
        <span class="fa fa-laptop"></span>
         
        Anonymity &amp; Decision Making
      </a>
    </li>
    <li>
      <a href="STA490research2.html">
        <span class="fa fa-clock"></span>
         
        Diurnal Pattern of Reaction Time
      </a>
    </li>
  </ul>
</li>
<li>
  <a href="https://public.tableau.com/profile/mcyn6666#!/">
    <span class="fa fa-edit"></span>
     
    Viz Projects
  </a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://drive.google.com/file/d/1ojQkeI0eUsXabGq6MvK1qK9n5jTHmJtL/view?usp=sharing">
    <span class="fa fa-file"></span>
     
    Resume
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">STA410 Statistical Computation</h1>

</div>


<div id="assignments" class="section level1 tabset">
<h1>Assignments</h1>
<div id="assignment-1" class="section level2">
<h2>Assignment 1</h2>
<p>Find the handout for this assignment <a href="https://drive.google.com/file/d/1Lzag_GE31H2RACTBGlQ7T_36K_N6JpBy/view?usp=sharing">here</a></p>
<p>The boat image can be found <a href="https://drive.google.com/file/d/1M6RvOdhBTz7wV5QOPQca2KHuxeHFMSPh/view?usp=sharing">here</a></p>
<p>The function <code>fwht2d</code> is provided by professor Knight:</p>
<pre class="r"><code>fwht2d &lt;- function(x) {
             h &lt;- 1
             len &lt;- ncol(x)
             while (h &lt; len) {
                for (i in seq(1,len,by=h*2)) {
                   for (j in seq(i,i+h-1)) {
                     a &lt;- x[,j]
                     b &lt;- x[,j+h]
                     x[,j] &lt;- a + b
                     x[,j+h] &lt;- a - b
                     }
                }
             h &lt;- 2*h
             }
             h &lt;- 1
             len &lt;- nrow(x)
             while (h &lt; len) {
                for (i in seq(1,len,by=h*2)) {
                   for (j in seq(i,i+h-1)) {
                     a &lt;- x[j,]
                     b &lt;- x[j+h,]
                     x[j,] &lt;- a + b
                     x[j+h,] &lt;- a - b
                     }
                }
             h &lt;- 2*h
             }
             x
             }</code></pre>
<div id="question-1" class="section level3">
<h3>Question 1</h3>
<div id="part-a" class="section level4">
<h4>Part (a)</h4>
<p><span class="math display">\[\hat{Z} = H_m  Z  H_n    ; (m = 2^k, n=2^l)\]</span> <span class="math display">\[H_m = H^T_m\]</span> <span class="math display">\[H_n = H^T_n\]</span> <span class="math display">\[H^{-1}_m = H_m / m\]</span> <span class="math display">\[H^{-1}_n = H_n / n\]</span> <span class="math display">\[ Z = H^{-1}_m \hat{Z} H^{-1}_n \]</span> <span class="math display">\[ Z = (H_m / m)  \hat{Z} (H_n / n)\]</span> <span class="math display">\[ Z = H_m \hat{Z} H_n / (mn)\]</span></p>
</div>
<div id="part-b" class="section level4">
<h4>Part (b)</h4>
<ul>
<li><p><code>fwht2d</code> : A function to compute Walsh-Hadamard Transform on the vector or matrix x.</p></li>
<li><p><code>hard.thresholding</code> : A function to apply hard-thresholding operator on the vector or matrix X, which lambda is the threshold value.</p></li>
</ul>
<pre class="r"><code>hard.thresholding &lt;- function(x, lambda) {
  u &lt;- fwht2d(x)
  u[abs(x) &lt;= lambda] &lt;- 0
  y &lt;- fwht2d(u)/length(x)
  return(y)
}</code></pre>
<ul>
<li><code>soft.thresholding</code> : A function to apply soft-thresholding operator on the vector or matrix X, which lambda is the threshold value.</li>
</ul>
<pre class="r"><code>soft.thresholding &lt;- function(x, lambda){
  u &lt;- fwht2d(x) 
  u &lt;- sign(u)*(pmax(abs(u)-lambda,0))
  y &lt;- fwht2d(u)/length(x) 
  return(y)
}</code></pre>
</div>
<div id="part-c" class="section level4">
<h4>Part (c)</h4>
<p>Original Image with No Thresholding Applied:</p>
<pre class="r"><code> boats &lt;- matrix(scan(&quot;C:/Users/miche/OneDrive/Desktop/UofT/STA410/Assignment 1/boats.txt&quot;),ncol=256,byrow=T) 
 image(boats, axes=F, col=grey(seq(0,1,length=256)))</code></pre>
<p><img src="STA410_files/figure-html/boat-1.png" width="672" /></p>
<p>When applying SOFT shrinkage to the image, with threshold = 25:</p>
<pre class="r"><code>a &lt;- soft.thresholding(boats, lambda=25)
 image(a, axes=F, col=grey(seq(0,1,length=256)))</code></pre>
<p><img src="STA410_files/figure-html/imagesoft-1.png" width="672" /></p>
<p>When applying HARD shrinkage to the image, with threshold = 0.35:</p>
<pre class="r"><code>b &lt;- hard.thresholding(boats, lambda=0.35)
 image(b, axes=F, col=grey(seq(0,1,length=256)))</code></pre>
<p><img src="STA410_files/figure-html/imagehard-1.png" width="672" /></p>
</div>
</div>
<div id="question-2" class="section level3">
<h3>Question 2</h3>
<div id="part-a-1" class="section level4">
<h4>Part (a)</h4>
<p><span class="math display">\[\phi_X(s) = E(s^{X_i})\]</span> <span class="math display">\[Y = \sum_{i=1}^{N} X_i\]</span> The probability generating function of Y <span class="math display">\[= E(s^Y)\]</span> <span class="math display">\[= \sum_{k=j}^{\infty} s^j P(Y=j)\]</span> <span class="math display">\[= \sum_{j=1}^{\infty} \sum_{k=1}^{\infty} s^j P(Y=j|N=k) P(N=k)) \]</span> <span class="math display">\[= \sum_{k=1}^{\infty} P(N=k)\sum_{j=1}^{\infty} s^j P(Y=j|N=k)\]</span> <span class="math display">\[=\sum_{k=1}^{\infty} P(N=k) \sum_{j=1}^{\infty} s^j P(X_1 +...+X_k=j)\]</span> <span class="math display">\[=[\sum_{k=1}^{\infty} P(N=k)]\cdot [E(s^{\sum_{i=1}^{k} X_i})]\]</span> <span class="math display">\[=[\sum_{k=1}^{\infty} P(N=k)]\cdot [E(s^{X_1})... E(s^{X_k})]\]</span> <span class="math display">\[=[\sum_{k=1}^{\infty} P(N=k)]\cdot [\phi(s) \times... \times\phi(s)]\]</span> <span class="math display">\[=[\sum_{k=1}^{\infty} P(N=k)]\cdot [\phi(s)]^k\]</span> <span class="math display">\[=\sum_{k=1}^{\infty} \frac{\lambda^ke^{-\lambda}}{k!}[\phi(s)]^k\]</span> <span class="math display">\[= e^{-\lambda}\sum_{k=1}^{\infty} \frac{[\lambda \cdot \phi(s)]^k}{k!}\]</span> <span class="math display">\[= e^{-\lambda} e^{\lambda \cdot \phi(s)} =e^{-\lambda+\lambda\phi(s)}\]</span> <span class="math display">\[= e^{-\lambda (1-\phi(s))}\]</span> Since <span class="math display">\[g(s)= e^{-\lambda(1-s)}\]</span> The PGF of Y is <span class="math display">\[g(\phi(s))= e^{-\lambda (1-\phi(s))}  \qquad \forall s \in \mathbf{R}\]</span></p>
</div>
<div id="part-b-1" class="section level4">
<h4>Part (b)</h4>
<p><span class="math display">\[ {X_i} \leq \ell\]</span> <span class="math display">\[Y=\sum_{i=1}^{N} X_i = X_1+...+X_N \leq  N \cdot\ell\]</span> <span class="math display">\[P(Y\geq M) \leq P(N \cdot \ell \geq M) = P(N\geq \frac{M}{\ell})\]</span> <span class="math display">\[m = \frac{M}{\ell} \Rightarrow M=m\ell\]</span> Substitute <span class="math display">\[M=m\ell\]</span>: <span class="math display">\[P(Y\geq m\ell) \leq P(N \geq m)\]</span> <span class="math display">\[P(Y\geq m\ell) \leq P(N \geq m) \leq \epsilon\]</span> <span class="math display">\[If \quad P(N\geq m) \leq \epsilon \quad, then\quad P(Y\geq m\ell) \leq \epsilon \]</span> <span class="math display">\[ M \geq m\ell\]</span></p>
</div>
<div id="part-c-1" class="section level4">
<h4>Part (c)</h4>
<p><span class="math display">\[P(Y\geq M)=P(s^Y \geq s^M) \leq \frac{E(s^Y)}{s^M} = \frac{exp(- \lambda (1-\phi(s)))}{s^M}\]</span> <span class="math display">\[For \quad P(Y \geq M) &lt; \epsilon: \]</span> <span class="math display">\[\epsilon = \frac{E(s^Y)}{s^M} = \frac{exp(- \lambda (1-\phi(s)))}{s^M}\]</span> <span class="math display">\[Thus, \quad s^M = \frac{E(s^Y)}{\epsilon} = \frac{exp(-\lambda(1-\phi(s)))}{\epsilon}\]</span> <span class="math display">\[ln(s^M) = ln[\frac{exp(-\lambda(1-\phi(s)))}{\epsilon}]\]</span> <span class="math display">\[ln(s^M) = ln[exp(-\lambda(1-\phi(s)))] - ln(\epsilon)\]</span> <span class="math display">\[ M \cdot ln(s)=-ln(\epsilon) -\lambda(1-\phi(s))\]</span> <span class="math display">\[M = \inf\limits_{s&gt;1} \frac{-ln(\epsilon)-\lambda(1-\phi(s))}{ln(s)}\]</span></p>
</div>
<div id="part-d" class="section level4">
<h4>Part (d)</h4>
<p>The R function for evaluating the distribution of Y:</p>
<pre class="r"><code>distY &lt;- function(lambda, p, M, epsilon=0.00001) {
  l &lt;- length(p)-1
  if(missing(M)){
    qp &lt;- qpois(1-epsilon, lambda)
    M &lt;- 2^ceil(log2(l*qp))
  }
  #{p(x)}
  p &lt;- c(p,rep(0, M-1-l)) 
  #Algorithm step 1: DFT of {p(x)} = phat(j)
  phat &lt;- fft(p)  
  #Algorithm step 2: DFT of Y= g(phat(j))
  ghat &lt;- exp(lambda*(phat-1)) 
   #Algorithm step 3: Dist of Y, P(Y=y)
  g &lt;- 1/M*Re(fft(ghat, inverse=TRUE))
  Y &lt;- list(y=c(0:(M-1)), probdist=g)
  return(Y)
}</code></pre>
<p>The distribution of <span class="math display">\[{X_i}\]</span>: <span class="math display">\[p(x)=P(X_i = x)= \frac{11-x}{66} \qquad for \quad x=0,...,10\]</span> Find the distribution of Y where <span class="math display">\[\lambda =3 \quad and\quad \epsilon = 10^{-5}\]</span> <span class="math display">\[S = \{ 1 &lt; s_1 &lt;s_2 &lt;...&lt;s_k\}\]</span> <span class="math display">\[M = \min\limits_{s \in S} \frac{-ln(\epsilon)-\lambda(1-\phi(s))}{ln(s)}\]</span></p>
<p>M is missing, so we first evaluate M, then find distribution of Y using the <code>distY</code> function:</p>
<pre class="r"><code># Dist of {Xi} = p(x)
p &lt;- (11-c(0:10))/66
# Take a discrete set of point S = {1&lt;s1&lt;...&lt;sk}
s &lt;- c(101:1000)/100
# Find probability generating function, phi(s)
pgf &lt;- p[1]
for (k in 1:10){
  pgf &lt;- pgf + (s^k)*p[k+1]
}
# Define M, lambda = 3
M &lt;- min((-log(0.00001)-3*(1-pgf))/log(s))
M</code></pre>
<pre><code>## [1] 67.24499</code></pre>
<pre class="r"><code>Y &lt;- distY(3,p,M)
Y</code></pre>
<pre><code>## $y
##  [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
## [26] 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49
## [51] 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66
## 
## $probdist
##  [1] 8.178613e-02 3.717557e-02 4.190695e-02 4.622869e-02 4.998671e-02
##  [6] 5.302037e-02 5.516429e-02 5.625044e-02 5.611032e-02 5.457743e-02
## [11] 5.148983e-02 4.669289e-02 4.375972e-02 4.053129e-02 3.710763e-02
## [16] 3.358954e-02 3.007472e-02 2.665363e-02 2.340512e-02 2.039181e-02
## [21] 1.765542e-02 1.521196e-02 1.304704e-02 1.111115e-02 9.399788e-03
## [26] 7.903182e-03 6.607413e-03 5.495610e-03 4.549147e-03 3.748789e-03
## [31] 3.075719e-03 2.512372e-03 2.043011e-03 1.653954e-03 1.333394e-03
## [36] 1.070721e-03 8.565542e-04 6.827321e-04 5.422487e-04 4.291627e-04
## [41] 3.384858e-04 2.660602e-04 2.084391e-04 1.627744e-04 1.267208e-04
## [46] 9.835611e-05 7.611565e-05 5.873388e-05 4.519253e-05 3.467611e-05
## [51] 2.653414e-05 2.024965e-05 1.541330e-05 1.170212e-05 8.862298e-06
## [56] 6.695145e-06 5.045721e-06 3.793620e-06 2.845576e-06 2.129564e-06
## [61] 1.590136e-06 1.184729e-06 8.807669e-07 6.533954e-07 4.837028e-07
## [66] 3.573408e-07 2.634525e-07</code></pre>
<pre class="r"><code>plot(Y$y, Y$probdist, type=&quot;p&quot;, main=&quot;Distribution of Y&quot;,xlab=&quot;x&quot;, ylab=&quot;probability&quot;)</code></pre>
<p><img src="STA410_files/figure-html/M-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="assignment-2" class="section level2">
<h2>Assignment 2</h2>
<p>Find the handout for this assignment <a href="https://drive.google.com/file/d/1tfDv_Tk45_O5kVUKh-IhH5ol0w7U-a8T/view?usp=sharing">here</a></p>
<div id="question-1-1" class="section level3">
<h3>Question 1</h3>
<div id="part-a-2" class="section level4">
<h4>Part (a)</h4>
<p>Generate a random variable <span class="math inline">\(X\)</span> from <span class="math inline">\(g(x;s)\)</span>: <span class="math display">\[g(x;s) = \frac{exp(x/s)}{s\{1+exp(x/s)\}^2}\]</span> <span class="math display">\[G(x;s)= -\frac{1}{1+exp(x/s)}\]</span> <span class="math display">\[U=G(x;s)= -\frac{1}{1+exp(x/s)}\]</span> <span class="math display">\[exp(x/s)= -\frac{1}{U} -1\]</span> <span class="math display">\[X = G^{-1}(U) =s \ ln(\frac{U}{1-U})\]</span></p>
</div>
<div id="part-b-2" class="section level4">
<h4>Part (b)</h4>
<p>The density function for <span class="math inline">\(f(x)\)</span> and <span class="math inline">\(g(x;s)\)</span> is:<br />
<span class="math display">\[f(x) = \frac{1}{\sqrt{2\pi}} exp(\frac{-x^2}{2})\]</span> <span class="math display">\[g(x;s) = \frac{exp(x/s)}{s\{1+exp(x/s)\}^2}\]</span> We want to find <span class="math inline">\(M(s)= \max\limits_{x} \frac{f(x)}{g(x;s)}\)</span>. We can find the maximum value of <span class="math inline">\(ln\frac{f(x)}{g(x;s)}\)</span> by maximizing <span class="math inline">\(ln f(x) - ln g(x;s)\)</span>:</p>
<p><span class="math display">\[ln f(x) - lng(x;s) = -ln(2\pi)-\frac{x^2}{2}-\frac{x}{s}+ln(s)+2ln[exp(x/s)+1]\]</span> <span class="math display">\[\frac{\partial}{\partial x} lnf(x)-lng(x;s) = -x-\frac{1}{s}+\frac{2exp(x/s)}{s[exp(x/s)+1]} \]</span> <span class="math display">\[\frac{\partial}{\partial x} lnf(x)-lng(x;s) = \frac{s(e^\frac{x}{s}+1)(x+\frac{1}{s})+2e^{\frac{x}{s}}}{s(e^\frac{x}{s}+1)}=0\]</span> <span class="math display">\[s(e^\frac{x}{s}+1)(x+\frac{1}{s})+2e^{\frac{x}{s}}=0\]</span> When x=0, the equation is solvable, x=0 is a critical point for this equation. <span class="math display">\[\frac{\partial ^2}{\partial ^2 x} lnf(x)-lng(x;s) = \frac{2e^\frac{x}{s}}{s^2(e^\frac{x}{s}+1)^2}-1 =0\]</span> When setting the second derivative to 0, we can solve s for the max/min value of <span class="math inline">\(lnf(x)-lng(x;s)\)</span>:<br />
<span class="math display">\[2e^\frac{x}{s}-s^2(e^\frac{x}{s}+1)^2 =0\]</span> Let <span class="math inline">\(t=e^\frac{x}{s}\)</span>, we get:<br />
<span class="math display">\[2t - s^2(t+1)^2 =2t-s^2(1+2t+t^2)=0\]</span> We then obtain a quadratic equation for s:<br />
<span class="math display">\[-s^2t^2+(-2s^2+2)t+(-s^2)=0\]</span> We then set the determinant <span class="math inline">\((b^2-4ac)\)</span> as 0:<br />
<span class="math display">\[(2-2s^2)^2-4s^4 =0\]</span> <span class="math display">\[4-8s^2 =0\]</span> Finally, we get <span class="math inline">\(s=1/\sqrt{2}\)</span>.<br />
<span class="math inline">\(M(s)\)</span> is minimized at x=0 when <span class="math inline">\(s=1/\sqrt{2}\)</span>, and maximized when <span class="math inline">\(s\geq 1/\sqrt{2}\)</span> because <span class="math inline">\(\frac{\partial ^2 M(s)}{\partial x^2} &lt; 0\)</span>.</p>
</div>
<div id="part-c-2" class="section level4">
<h4>Part (c)</h4>
<p>The value of s that minimizes <span class="math inline">\(M(s)\)</span> is 0.648</p>
<pre class="r"><code>s &lt;- c(1:1000)/1000 # generates values 0, 0.001,..., 0.999, 1
x &lt;- c(0:3000)/1000 # generates values 0, 0.001, 0.002 ,..., 2.999, 3 
group &lt;- c(rep(0,1000))
for(i in s){
  group[i*1000] &lt;- max(dnorm(x)/dlogis(x, location=0, scale=i))}
min_s &lt;- which(group==min(group))/1000
min_s</code></pre>
<pre><code>## [1] 0.648</code></pre>
</div>
</div>
<div id="question-2-1" class="section level3">
<h3>Question 2</h3>
<div id="part-a-3" class="section level4">
<h4>Part (a)</h4>
<p>Differentiating the objective function with respect to <span class="math inline">\(\theta_1\)</span>,…,<span class="math inline">\(\theta_n\)</span>:</p>
<p><span class="math display">\[\frac{\partial}{\partial \theta_j}\{ \sum_{i=1}^{n} (y_i - \theta_i )^2 + \lambda \sum_{i=2}^{n-1}(\theta_{i+1} - 2\theta_i + \theta_{i-1})^2\}\]</span> <span class="math display">\[\begin{align}
&amp;= -2(y_1 - \theta_1) +2\lambda(\theta_3 - 2\theta_2 + \theta_1)\\
&amp;= -2(y_2 - \theta_2)+2\lambda(\theta_4 -2\theta_3+\theta_2)-4\lambda(\theta_3-2\theta_2+\theta_1)\\
&amp;= -2(y_j-\theta_j)+2\lambda(\theta_j -2\theta_{j-1} + \theta_{j-2}) -4\lambda(\theta_{j+1}-2\theta_j+\theta_{j-1})\\
&amp;= -2(y_{n-1}-\theta_{n-1})+2\lambda(\theta_{n-1}-2\theta_{n-2}+\theta_{n-3})-4\lambda(\theta_n -2\theta_{n-1}+\theta_{n-2})\\
&amp;= -2(y_n - \theta_n) + 2\lambda(\theta_n - 2\theta_{n-1} + \theta_{n-2})
\end{align}\]</span></p>
<p>Setting these partial derivatives to 0, it follows that <span class="math inline">\(\hat{\theta_1},...,\hat{\theta_n}\)</span> satisfy the equations.</p>
<p><span class="math display">\[\begin{align}
y_1 &amp;= (1+\lambda)\hat{\theta_1}-2\lambda\hat{\theta_2} +\lambda\hat{\theta_3} \\
y_2 &amp;= -2\lambda\hat{\theta_1}+(1+5\lambda)\hat{\theta_2}-4\lambda\hat{\theta_3}+\lambda\hat{\theta_4}\\
y_j &amp;= \lambda\hat{\theta_{j-2}}-4\lambda\hat{\theta_{j-1}}+(1+6\lambda)\hat{\theta_j}-4\lambda\hat{\theta_{j+1}}+\lambda\hat{\theta_{j+2}} \qquad for \quad j = 3,...,n-2\\
y_{n-1} &amp;= \lambda\hat{\theta_{n-3}} - 4\lambda\hat{\theta_{n-2}} +(1+5\lambda)\hat{\theta_{n-1}} - 2\lambda\hat{\theta_n}\\
y_n &amp;= \lambda\hat{\theta_{n-2}} - 2\lambda\hat{\theta_{n-1}} +(1+\lambda)\hat{\theta_n}
\end{align}\]</span></p>
</div>
<div id="part-b-3" class="section level4">
<h4>Part (b)</h4>
<p>The linear equation can be written as <span class="math display">\[\mathbf{y} = \mathbf{A_\lambda} \hat{\theta} \]</span>:</p>
<p><span class="math display">\[\mathbf{A_\lambda} = \left[\begin{array}
{rrr}
1+\lambda &amp; -2\lambda &amp; \lambda &amp; ... &amp; 0 &amp; 0 \\
-2\lambda &amp; 1+5\lambda &amp; -4\lambda &amp; ... &amp; 0 &amp; 0 \\
\lambda &amp; -4\lambda &amp; 1+6\lambda &amp; ... &amp; 0 &amp; 0 \\
0 &amp; \lambda &amp; -4\lambda &amp; ... &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; \lambda &amp; ... &amp; 0 &amp; 0\\
\vdots &amp; \ddots &amp; \ddots &amp; \ddots &amp; \cdots &amp; \vdots \\
0 &amp; 0&amp; 0 &amp; ...&amp; \lambda &amp; 0\\
0 &amp;0&amp;0&amp;...&amp; -4\lambda &amp; \lambda \\
0&amp;0&amp;0&amp;...&amp; 1+5\lambda &amp; -2\lambda\\
0&amp;0&amp;0&amp;...&amp; -2\lambda &amp; 1+\lambda\\
\end{array}\right]\]</span></p>
<p>To show <span class="math inline">\(\lambda=1\)</span>, we need to prove <span class="math inline">\(\mathbf{A_\lambda} y=y\)</span>. We subsittute <span class="math inline">\(y_i=ax_i +b \quad\forall i\)</span> into the equation:</p>
<p><span class="math display">\[\mathbf{A_\lambda y}=\left[\begin{array}
{rrr}
1+\lambda &amp; -2\lambda &amp; \lambda &amp; ... &amp; 0 &amp; 0 \\
-2\lambda &amp; 1+5\lambda &amp; -4\lambda &amp; ... &amp; 0 &amp; 0 \\
\lambda &amp; -4\lambda &amp; 1+6\lambda &amp; ... &amp; 0 &amp; 0 \\
0 &amp; \lambda &amp; -4\lambda &amp; ... &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; \lambda &amp; ... &amp; 0 &amp; 0\\
\vdots &amp; \ddots &amp; \ddots &amp; \ddots &amp; \cdots &amp; \vdots \\
0 &amp; 0&amp; 0 &amp; ...&amp; \lambda &amp; 0\\
0 &amp;0&amp;0&amp;...&amp; -4\lambda &amp; \lambda \\
0&amp;0&amp;0&amp;...&amp; 1+5\lambda &amp; -2\lambda\\
0&amp;0&amp;0&amp;...&amp; -2\lambda &amp; 1+\lambda\\
\end{array}\right]
\left[\begin{array}
{rrr}
a+b\\
2a+b\\
\vdots\\
\vdots\\
na+b
\end{array}\right]\]</span></p>
<p>Then we have:</p>
<ul>
<li>first entry of <span class="math inline">\(\mathbf{Ay}\)</span> = <span class="math inline">\((1+\lambda)(a+b)-2\lambda(2a+b)+\lambda(3a+b) = a+b = y_1\)</span><br />
</li>
<li>second entry of <span class="math inline">\(\mathbf{Ay}\)</span> = <span class="math inline">\(-2\lambda(a+b)+(1+5\lambda)(2a+b)-4\lambda(3a+b)+\lambda(4a+b) = 2a+b = y_2\)</span><br />
</li>
<li>continue til the n-th entry of <span class="math inline">\(\mathbf{Ay}\)</span><br />
</li>
<li>Finally, we get <span class="math inline">\(\mathbf{Ay}=\mathbf{y}\)</span> and we see that <span class="math inline">\(\lambda=1\)</span>.<br />
</li>
<li>If <span class="math inline">\(\{y_i\}\)</span> are exactly linear, then <span class="math inline">\(\hat{\theta_i} = y_i \quad \forall i\)</span>.</li>
</ul>
</div>
<div id="part-c-3" class="section level4">
<h4>Part (c)</h4>
<p>Gauss-Seidel algorithm can be used to compute the estimates:<br />
- The matrix A is strict diagonally dominant, so both the Gauss-Seidel and Jacobi algorithms converge.<br />
- The objective function is a sum of two quadratic functions in <span class="math inline">\(\theta_1\)</span>,…,<span class="math inline">\(\theta_n\)</span>, so the Hessian matrix = sum of the Hessians of the two quadratic functions.<br />
- The Hessian matrix of the first term <span class="math inline">\(\sum_{i=1}^{n} (y_i-\theta_i)^2\)</span> is <span class="math inline">\(2I\)</span>, so H is positive definite.<br />
- The second term <span class="math inline">\(\sum_{i=2}^{n-1}(\theta_{i+1} - 2\theta_i + \theta_{i-1})^2\)</span> is non-negative, so it has a positive definite Hessian. - The matrix A is positive definite.</p>
</div>
<div id="part-d-1" class="section level4">
<h4>Part (d)</h4>
<p>The following is a template of R function used to estimate the parameters:</p>
<pre class="r"><code>seidel &lt;- function(y,lambda,theta,max.iter=50,eps=1.e-6) {
          n &lt;- length(y)
# Define initial estimates if unspecified 
          if (missing(theta)) theta &lt;- y
# Compute objective function for initial estimates
          obj &lt;- sum((y-theta)^2)+lambda*sum(diff(diff(theta))^2)
# The function diff(diff(theta)) computes second differences of the vector 
# theta
          no.conv &lt;- T
# You will need to define convergence (no.conv==F) somehow - either in
# terms of the objective function or in terms of the estimates
# Do Gauss-Seidel iteration until convergence or until max.iter iterations
          iter &lt;- 0
          theta.old &lt;- theta
          while(no.conv) {  
            theta[1] &lt;-  (y[1]+2*lambda*theta[2]-lambda*theta[3])/(1+lambda)
            theta[2] &lt;- (y[2]+2*lambda*theta[1]+4*lambda*theta[3]-lambda*theta[4])/(1+5*lambda)
# Update theta[2],..., theta[n-1]
            for (j in 3:(n-2)) {
                theta[j] &lt;-  (y[j]-lambda*theta[j-2]+4*lambda*theta[j-1]+4*lambda*theta[j+1]-lambda*theta[j+2])/(1+6*lambda)
                }     
             theta[n-1] &lt;- (y[n-1]-lambda*theta[n-3]+4*lambda*theta[n-2]+2*lambda*theta[n])/(1+5*lambda)
             theta[n] &lt;- (y[n]-lambda*theta[n-2]+2*lambda*theta[n-1])/(1+lambda)
# Compute new objective function for current estimates
             obj.new &lt;- sum((y-theta)^2)+lambda*sum(diff(diff(theta))^2)
             iter &lt;- iter + 1
# Now set no.conv to F if either convergence or iter=max.iter
# and update the value of the objective function variable obj
              if (abs(obj.new-obj)&lt;eps) no.conv &lt;- F
              if (iter==max.iter) no.conv &lt;- F
              obj &lt;- obj.new
              theta.old &lt;- theta
              }
           r &lt;- list(y=y,theta=theta,obj=obj,niters=iter)
           r
           }</code></pre>
<p>The following commands produce estimates of <span class="math inline">\(\theta_1 ,...,\theta_{1000}\)</span> for <span class="math inline">\(\lambda = 1,10,100\)</span>. Matrix A becomes less diagonally dominant for larger <span class="math inline">\(\lambda\)</span>, so the Gauss-seidel algorithm will take longer to converge. Maximum iterations increases as <span class="math inline">\(\lambda\)</span> increases.</p>
<pre class="r"><code>x &lt;- c(1:1000)/1000
y &lt;- cos(6*pi*x)*exp(-2*x) + rnorm(1000,0,0.05)
gs1 &lt;- seidel(y, lambda=1)
gs10 &lt;- seidel(y, lambda=10, theta=gs1$theta, max.iter=100)
gs100 &lt;- seidel(y, lambda=100, theta=gs10$theta, max.iter=1000)
plot(y,pch=&quot;.&quot;, cex=3)
lines(gs1$theta, col=&quot;blue&quot;, lwd=3)
lines(gs10$theta, col=&quot;red&quot;, lwd=3)
lines(gs100$theta, col=&quot;green&quot;, lwd=3)</code></pre>
<p><img src="STA410_files/figure-html/gs-1.png" width="672" /></p>
<p>The plot above shows that as <span class="math inline">\(\lambda\)</span> increases, the estimate fluctuates at a decreasing range.</p>
</div>
</div>
</div>
<div id="assignment-3" class="section level2">
<h2>Assignment 3</h2>
<p>Find the handout for this assignment <a href="https://drive.google.com/file/d/1M-gXUvv14Mc-UiZumrzrMxTGdQVJNiaZ/view?usp=sharing">here</a></p>
<p>The function <code>leverage</code> is provided by professor Knight.</p>
<div id="question-1-2" class="section level3">
<h3>Question 1</h3>
<div id="part-a-4" class="section level4">
<h4>Part (a)</h4>
<p><span class="math display">\[Var(\widehat{tr(A))} = E[(\mathbf{V}^T A \mathbf{V})^2]-tr(A)^2\]</span> It suffices to minimize <span class="math display">\[E[(\mathbf{V}^T A \mathbf{V})^2]= \sum_{i=1}^{n}\sum_{j=1}^{n}\sum_{k=1}^{n}\sum_{\ell=1}^{n} a_{ij} a_{k\ell} E(V_i V_j V_k V_\ell)\]</span><br />
Assume that <span class="math inline">\(V_1,...,V_n\)</span> are independent with mean 0 and variance 1, <span class="math inline">\(E(V_i V_j V_k V_\ell) = 0 \quad or \quad 1\)</span> unless <span class="math inline">\(i=j=k=\ell\)</span></p>
<p>Therefore, <span class="math display">\[E[(\mathbf{V}^T A \mathbf{V})^2]= \sum_{i=1}^{n} a_{ii}^2 E(V_i^4) + constant\]</span><br />
This suffices to find a distribution with mean 0 and variance 1 with minimal fourth moment: <span class="math display">\[E(V_i^4) = Var(V_i^2) +1\]</span></p>
<ul>
<li><span class="math inline">\(Var(V_i^2)\)</span> is mininized if <span class="math inline">\(V_i^2\)</span> is constant with probability 1.<br />
</li>
<li>Since <span class="math inline">\(E(V_i) =0\)</span> and <span class="math inline">\(E(V_i^2)=1\)</span>, <span class="math inline">\(Var(\widehat{tr(S)})\)</span> is minimized by taking the elements of <span class="math inline">\(\mathbf{V_i}\)</span> to be <span class="math inline">\(\pm1\)</span> each with probability 1/2.</li>
</ul>
</div>
<div id="part-b-4" class="section level4">
<h4>Part (b)</h4>
<p><span class="math display">\[H= \left(\begin{array}
{rr}
H_{11} &amp; H_{12} \\
H_{21} &amp; H_{22} \end{array}\right)\]</span> <span class="math display">\[\left(\begin{array}
{rr}
H_{11} &amp; H_{12} \\
H_{21} &amp; H_{22} \end{array}\right)
\left(\begin{array}
{rr}
\mathbf{V} \\
\mathbf{0} \end{array}\right) = 
\left(\begin{array}
{rr}
H_{11}\times\mathbf{V} + H_{12} \times\mathbf{0} \\
H_{21}\times\mathbf{V} + H_{22} \times\mathbf{0}
\end{array}\right) = 
\left(\begin{array}
{rr}
H_{11}\mathbf{V} \\
H_{21}\mathbf{V}
\end{array}\right)\]</span> <span class="math display">\[\left(\begin{array}
{rr}
H_{11} &amp; H_{12} \\
H_{21} &amp; H_{22} \end{array}\right)
\left(\begin{array}
{rr}
H_{11}^{k-1}\mathbf{V} \\
\mathbf{0} \end{array}\right) = 
\left(\begin{array}
{rr}
H_{11}\times H_{11}^{k-1}\mathbf{V} + H_{12} \times\mathbf{0} \\
H_{21}\times H_{11}^{k-1}\mathbf{V} + H_{22} \times\mathbf{0}
\end{array}\right) = 
\left(\begin{array}
{rr}
H_{11}^k\mathbf{V} \\
H_{21}H_{11}^{k-1}\mathbf{V}
\end{array}\right)\]</span></p>
</div>
<div id="part-c-4" class="section level4">
<h4>Part (c)</h4>
<p>To compute the leverage:</p>
<pre class="r"><code>library(splines) # loads the library of functions to compute B-splines 

leverage &lt;- function(x,w,r=10,m=100) {
               qrx &lt;- qr(x)
               n &lt;- nrow(x)
               lev &lt;- NULL
               for (i in 1:m) {
                   v &lt;- ifelse(runif(n)&gt;0.5,1,-1)
                   v[-w] &lt;- 0
                   v0 &lt;- qr.fitted(qrx,v)
                   f &lt;- v0
                   for (j in 2:r) {
                      v0[-w] &lt;- 0
                      v0 &lt;- qr.fitted(qrx,v0)
                      f &lt;- f + v0/j
                      }
                   lev &lt;- c(lev,sum(v*f))
                   }
                std.err &lt;- exp(-mean(lev))*sd(lev)/sqrt(m)
                lev &lt;- 1 - exp(-mean(lev))
                r &lt;- list(lev=lev,std.err=std.err)
                r
}

set.seed(10)
x &lt;- c(1:1000)/1000 
X1 &lt;- 1 
for (i in 1:10){
  X1 &lt;- cbind(X1,x^i)
  } 

X2 &lt;- cbind(1,bs(x,df=10))
w &lt;- c(1:100)

leverage(X1[,3:11],w)</code></pre>
<pre><code>## $lev
## [1] 0.5627272
## 
## $std.err
## [1] 0.04305275</code></pre>
<pre class="r"><code>leverage(X2[,3:11],w)</code></pre>
<pre><code>## $lev
## [1] 0.2043459
## 
## $std.err
## [1] 0.02491546</code></pre>
<p>The points in first design <span class="math inline">\(g_1(x)\)</span> have greater leverage.</p>
</div>
</div>
<div id="question-2-2" class="section level3">
<h3>Question 2</h3>
<div id="part-a-5" class="section level4">
<h4>Part (a)</h4>
<p>X has a Gamma distribution, so <span class="math inline">\(E(X)= \frac{\alpha}{\lambda}\)</span> and <span class="math inline">\(Var(X)=\frac{\alpha}{\lambda^2}\)</span></p>
<p>Arranging the variables gives us: <span class="math inline">\(\alpha= \frac{E(X)^2}{Var(X)} \qquad \lambda= \frac{E(X)}{Var(X)}\)</span></p>
<p>Then, if the sample mean is <span class="math inline">\(\bar{x}\)</span> and the sample variance of <span class="math inline">\(x_1,...,x_n\)</span> is <span class="math inline">\(s^2\)</span>, the method of moments estimators are <span class="math inline">\(\widehat\alpha = \frac{\bar{x}^2}{s^2}\)</span> and <span class="math inline">\(\widehat{\lambda}=\frac{\bar{x}}{s^2}\)</span></p>
</div>
<div id="part-b-5" class="section level4">
<h4>Part (b)</h4>
<p>Let <span class="math inline">\(\phi(\alpha)\)</span> be the digamma function and <span class="math inline">\(\phi&#39;(\alpha)\)</span> be the trigamma function. They are the first two derivatives of ln<span class="math inline">\(\Gamma(\alpha)\)</span>.</p>
<p>The score vector for fixed <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\lambda\)</span>:<br />
<span class="math display">\[ \left(\begin{array}
{r}
\sum_{i=1}^{n} ln(x_i) + n[ln(\lambda)-\phi(\alpha)] \\
\frac{n\alpha}{\lambda} - \sum_{i=1}^{n} x_i
\end{array}\right)\]</span></p>
<p>The Fisher information matrix:<br />
<span class="math display">\[\left(\begin{array}
{rrr}
n\phi&#39;(\alpha) &amp; \frac{-n}{\lambda} \\
\frac{-n}{\lambda} &amp; \frac{n\alpha}{\lambda^2}
\end{array}\right)\]</span></p>
<p>R function that compute MLE:</p>
<pre class="r"><code>mle.gamma &lt;- function(x, eps=1.e-6){
  n &lt;- length(x)
  lambda &lt;- mean(x)/var(x)
  alpha &lt;- mean(x)^2/var(x)
  alpha1 &lt;- alpha
  theta &lt;- c(alpha,lambda)
  theta0 &lt;- theta
  s1 &lt;- sum(log(x))+n*(log(lambda)-digamma(alpha))
  s2 &lt;- n*alpha/lambda-sum(x)
  score &lt;- c(s1,s2)
  pstep &lt;- 0
  iter &lt;- 0
  while (max(abs(score)) &gt; eps){
    fisher11 &lt;- n*trigamma(alpha)
    fisher12 &lt;- -n/lambda
    fisher22 &lt;- n*alpha/lambda^2
    fisher &lt;- matrix(c(fisher11,fisher12,fisher12,fisher22),ncol=2)
    mtp &lt;- 1
    repeat {
      theta1 &lt;- theta + mtp*solve(fisher,score)
      if (min(theta1) &lt;=0){
        mtp &lt;- 0.9*mtp
        pstep &lt;- pstep+1
        }
      else break
      }
    theta &lt;- theta1
    alpha &lt;- theta[1]
    lambda &lt;- theta[2]
    s1 &lt;- sum(log(x)) + n*(log(lambda)-digamma(alpha))
    s2 &lt;- n*alpha/lambda-sum(x)
    score &lt;- c(s1,s2)
    iter &lt;- iter+1
    if (iter==1) theta2 &lt;- theta
    }
  fisher11&lt;- n*trigamma(alpha)
  fisher12 &lt;- -n/lambda
  fisher22 &lt;- n*alpha/lambda^2
  fisher &lt;- matrix(c(fisher11,fisher12,fisher12,fisher22),ncol=2)
  cat(&quot;number of iterations =&quot;, iter, &quot;\n&quot;)
  r &lt;- list(mle=theta, varcovar=solve(fisher))
  r
  }</code></pre>
<p>When <span class="math inline">\(n=100\)</span> with <span class="math inline">\(\alpha=0.5\)</span> and <span class="math inline">\(\lambda=1\)</span>:</p>
<pre class="r"><code>x &lt;- rgamma(100, shape=0.5)
r &lt;- mle.gamma(x)</code></pre>
<pre><code>## number of iterations = 5</code></pre>
<pre class="r"><code>r</code></pre>
<pre><code>## $mle
## [1] 0.4326962 0.8692845
## 
## $varcovar
##             [,1]        [,2]
## [1,] 0.002485084 0.004992521
## [2,] 0.004992521 0.027493832</code></pre>
<p>When <span class="math inline">\(n=100\)</span> with <span class="math inline">\(\alpha=10\)</span> and <span class="math inline">\(\lambda=1\)</span>:</p>
<pre class="r"><code>x &lt;- rgamma(100, shape=10)
r &lt;- mle.gamma(x)</code></pre>
<pre><code>## number of iterations = 3</code></pre>
<pre class="r"><code>r</code></pre>
<pre><code>## $mle
## [1] 10.111166  1.003178
## 
## $varcovar
##           [,1]       [,2]
## [1,] 1.9795797 0.19640378
## [2,] 0.1964038 0.02048148</code></pre>
</div>
</div>
</div>
<div id="assignment-4" class="section level2">
<h2>Assignment 4</h2>
<p>Find the handout for this assignment <a href="https://drive.google.com/file/d/1pbTR4qYWnFNNuzOwn7J59JcVstJUrUaE/view?usp=sharing">here</a></p>
<div id="question-1-3" class="section level3">
<h3>Question 1</h3>
<div id="part-a-6" class="section level4">
<h4>Part (a)</h4>
<p><span class="math display">\[\theta_2 = (\theta_2-\theta_1)+\theta_1 = \phi_2 + \theta_1\]</span> Therefore, <span class="math display">\[\begin{align}
\theta_k &amp;= \theta_1 + (\theta_2-\theta_1) +  (\theta_3-\theta_2) +  (\theta_4-\theta_3) + ... + (\theta_k-\theta_{k-1}) \\
&amp;= \theta_1 + \sum_{i=2}^{k} \phi_i
\end{align}\]</span></p>
</div>
<div id="part-b-6" class="section level4">
<h4>Part (b)</h4>
<p>We first differentiate the objective function with respect to <span class="math inline">\(\theta_1\)</span>:<br />
<span class="math display">\[\frac{\partial}{\partial \theta_1} [\sum_{i=1}^{n}(y_i - \theta_1 - \sum_{j=2}^{i} \phi_j)^2 + \lambda \sum_{i=2}^{n} |\phi_i|]=-2\sum_{i=1}^{n}(y_i-\theta_1-\sum_{j=2}^{i}\phi_j)\]</span><br />
Then, we make the above partial derivative to be equal to 0. For fixed values of <span class="math inline">\(\phi_2,...,\phi_n\)</span>, the objective function is minimized at:<br />
<span class="math display">\[\theta_1 = \frac{1}{n} \sum_{i=1}^{n}(y_i - \sum_{j=2}^{i}\phi_j)\]</span></p>
</div>
<div id="part-c-5" class="section level4">
<h4>Part (c)</h4>
<p>The objective function can be expressed as a sum of differentiable and a non-differentiable convex function.<br />
The derivative of the differentiable function:<br />
<span class="math display">\[-2\sum_{i=j}^{n}(y_i-\theta_1-\sum_{k=2}^{i}\phi_k)\]</span></p>
<p>Then, the subgradient of <span class="math inline">\(\lambda|\phi_j|\)</span> in the non-differetiable function translated by the derivative of the differentiable function, is:<br />
<span class="math display">\[\begin{align}
\partial  \lambda|\phi_j|= \lambda\partial|\phi_j|&amp;= +\lambda \quad if \quad \phi_j &gt;0\\
&amp;= [-\lambda,+\lambda] \quad if \quad \phi_j =0\\
&amp;= -\lambda \quad if \quad \phi_j &lt;0
\end{align}\]</span></p>
<p>The first terms <span class="math inline">\(j-1\)</span> of the summation are independent of <span class="math inline">\(\phi_j\)</span>, thus the convex function is minimized if only if the subgradient at the minimizing point contains zero. The convex function is minimized at <span class="math inline">\(\phi_j=0\)</span> if:<br />
<span class="math display">\[2\sum_{i=j}^{n} (y_i - \theta_1- \sum_{k=2,k\neq j}^{i} \phi_k) \quad \in[-\lambda,+\lambda]\]</span> leading to <span class="math display">\[\phi_j = 0 \quad if \quad |\sum_{i=j}^{n} (y_i - \theta_1- \sum_{k=2,k\neq j}^{i} \phi_k)| \leq \frac{\lambda}{2}\]</span></p>
<p>If that condition is not satisfied, we have:<br />
<span class="math display">\[\phi_j = \frac{1}{n-(j-1)}[\sum_{i=j}^{n}(y_i-\theta_1-\sum_{k=2,k\neq j}^{i} \phi_k)-\frac{\lambda}{2}] \quad  if \quad \sum_{i=j}^{n}(y_i-\theta_1-\sum_{k=2,k\neq j}^{i} \phi_k) &gt; \frac{\lambda}{2}\]</span></p>
<p>Else if:<br />
<span class="math display">\[\phi_j = \frac{1}{n-(j-1)}[\sum_{i=j}^{n}(y_i-\theta_1-\sum_{k=2,k\neq j}^{i} \phi_k)+\frac{\lambda}{2}] \quad  if \quad \sum_{i=j}^{n}(y_i-\theta_1-\sum_{k=2,k\neq j}^{i} \phi_k) &lt; -\frac{\lambda}{2}\]</span></p>
</div>
<div id="part-d-2" class="section level4">
<h4>Part (d)</h4>
<p>A function in R implementing the coordinate descent algorithm suggested in parts (b) and (c):</p>
<pre class="r"><code>coor.des &lt;- function(y,lambda,theta, max.iter=500, eps=1.e-3){
  n &lt;- length(y)
  if (missing(theta)) theta &lt;- y
  theta &lt;- c(theta[1], diff(theta))
  yhat &lt;- cumsum(theta)
  obj &lt;- sum((yhat)^2) + lambda*sum(abs(theta[2:n]))
  no.conv &lt;- T
  iter &lt;- 0
  while(no.conv){
    theta[1] &lt;- mean(y-yhat + theta[1])
    yhat &lt;- cumsum(theta)
    for (j in 2:n){
      yj &lt;- y[j:n] - yhat[j:n] + theta[j]
      myj &lt;- mean(yj)
      lambdaj &lt;- lambda/(2*(n-j+1))
      if (abs(myj) &lt;= lambdaj) theta[j] &lt;- 0
      else theta[j] &lt;- myj-lambdaj*sign(myj)
      yhat &lt;- cumsum(theta)
    }
    new.obj &lt;- sum((y-yhat)^2) + lambda*sum(abs(theta[2:n]))
    iter &lt;- iter + 1
    if (abs(new.obj - obj) &lt; eps) no.conv &lt;- F
    if (iter==max.iter) no.conv &lt;- F
    obj &lt;- new.obj
  }
  r &lt;- list(y=y, theta=yhat, numberofiter=iter, obj=obj)
  r
}</code></pre>
<p>Test the function on the data generated as follows,and the figure below shows the data with the estimates for <span class="math inline">\(\lambda=5\)</span>:</p>
<pre class="r"><code>y &lt;- c(rep(0,250),rep(1,250),rep(0,50),rep(1,450)) + rnorm(1000,0,0.1)
m1 &lt;- coor.des(y, lambda=5, max.iter=500)
plot(y)
lines(m1$theta, lwd=5, col=&quot;blue&quot;)</code></pre>
<p><img src="STA410_files/figure-html/1dtest-1.png" width="672" /></p>
</div>
</div>
<div id="question-2-3" class="section level3">
<h3>Question 2</h3>
<ol style="list-style-type: lower-alpha">
<li><p>We first decompose the log-likelihood into two parts:<br />
<span class="math display">\[lnL=\sum_{k=1}^{m}\sum_{i=1}^{n} u_{ik}ln[f_k(x_i)]+\sum_{k=1}^{m}\sum_{i=1}^{n} u_{ik}ln(\lambda_k)\]</span><br />
With the constraint <span class="math inline">\(\lambda_1 +...+\lambda_m =1\)</span>, we maximize <span class="math inline">\(\lambda_k\)</span> and have:<br />
<span class="math display">\[\hat \lambda_k = \frac{1}{n}\sum_{i=1}^{n} u_{ik}\]</span><br />
Then we maximize <span class="math inline">\(\mu_k\)</span>:<br />
<span class="math display">\[\hat\mu_k = (\sum_{i=1}^{n} u_{ik})^{-1}\sum_{i=1}^{n} u_{ik}x_i\]</span> Maximazing over <span class="math inline">\(\sigma_k^2\)</span>, we have:<br />
<span class="math display">\[ \hat\sigma_k^2=(\sum_{i=1}^{n} u_{ik})^{-1}\sum_{i=1}^{n} u_{ik}(x_i-\hat\mu_k)^2\]</span><br />
The unobserved <span class="math inline">\(\{u_{ik}\}\)</span> in EM algorithm is estimated by <span class="math display">\[\hat u_{ik} = \frac{\hat\lambda_k \hat f_k(x_i)}{\hat\lambda_1\hat f_1(x_i)+...+\hat\lambda_m\hat f_m(x_i)}\]</span></p></li>
<li><p>R function that uses the EM algorithm to compute the MLEs of <span class="math inline">\(\lambda_1,...,\lambda_m\)</span>, <span class="math inline">\(\mu_1,...,\mu_m\)</span> and <span class="math inline">\(\sigma_1^2,...,\sigma_m^2\)</span>:</p></li>
</ol>
<pre class="r"><code>normalmixture &lt;- function(x,k,mu,sigma,lambda,em.iter=50) {
#  This function inputs the data (x) and the number of components (k)
# as well as initials estimates for the means (mu), std deviations (sigma),
# and probabilities (lambda).  You should also include arguments for 
# determining convergence although here I just have a fixed number of
# iterations (em.iter) of the EM algorithm with a default of 50 iterations
         n &lt;- length(x)
         x &lt;- sort(x)
         vars &lt;- sigma^2
         means &lt;- mu
         lam &lt;- lambda/sum(lambda)  # guarantee that lambdas sum to 1
         delta &lt;- matrix(rep(0,n*k),ncol=k) 
         loglikk &lt;- NULL
# In this template, we have a fixed number of EM iterations; you may want 
# to have a more refined convergence criterion 
         for (s in 1:em.iter) {
           loglik &lt;- 0
# compute updates of deltas 
             for (i in 1:n) {
                xi &lt;- x[i]
                for (j in 1:k) {
                   mj &lt;- means[j]
                   varj &lt;- vars[j]
                   denom &lt;- 0
                   for (u in 1:k) {
                      mu &lt;- means[u]
                      varu &lt;- vars[u]
                      denom &lt;- denom + lam[u]*dnorm(xi,mu,sqrt(varu))
                   }
                   loglik &lt;- loglik + log(denom)
                   delta[i,j] &lt;- lam[j]*dnorm(xi,mj,sqrt(varj))/denom
                   }
                   }
# compute updated estimates of means, variances, and probabilities - the 
# function weighted.mean may be useful here for computing the estimates of
# the means and variances.
              for (j in 1:k) {
                  deltaj &lt;- as.vector(delta[,j])
                  lambda[j] &lt;- sum(deltaj)/n
                  mj &lt;- weighted.mean(x, w=deltaj)
                  means[j] &lt;- mj
                  varj &lt;-  weighted.mean((x-mj)^2, w=deltaj)
                  vars[j] &lt;- varj
                  }
             }
# Log-likelihood computation - you may want to compute this after each EM
# iteration (i.e. within the outer loop)
        loglik &lt;- c(loglikk, loglik)        
        r &lt;- list(mu=means,var=vars,delta=delta,lambda=lambda,loglik=loglik)
        r
     }</code></pre>
<ol start="3" style="list-style-type: lower-alpha">
<li>We first plot a kernel density estimate of the data with the bandwidth chosen to display an interesting number of modes. The below figure shows the estimate computed by R function <code>density</code> with the bandwidth for the Gaussian Kernel set to 4 (for m=3) and 5 (for m=2). Using the approximate local minima of this kernel density estimate, we can define bins which we will use to define the initial estimates:</li>
</ol>
<pre class="r"><code>buffsnow &lt;- c(64.7,114.8, 90.8, 54.9, 67.3, 22.4 ,57.3, 80.9 ,74.3, 89.9 ,74.5 ,72 ,50.2 ,51 ,69.8 ,99.1, 96.6, 102.4 ,74.1, 108.5, 86.7, 53.4, 53.5, 70.3, 78.5, 126.4, 82.4 ,78.1 ,51.1, 90.9, 76.2, 104.5, 87.4 ,110.5, 25, 69.3, 53.5, 39.8, 63.6 ,46.7, 72.9 ,79.6, 83.6, 80.7 ,60.3, 79, 74.4, 49.6, 54.7, 71.8,49.1, 103.9 ,51.6, 82.4, 83.6, 77.8 ,79.3, 89.6 ,85.5 ,58 ,120.7, 110.5 ,65.4 ,39.9, 40.1, 88.7, 71.4, 83, 55.9, 89.9, 84.8, 105.2, 113.7 ,124.7 ,114.5, 115.6, 102.4, 101.4 ,89.8, 71.5,
70.9 ,98.3, 66.1, 71.6, 78.4 ,120.5, 97, 109.9, 78.8, 88.7, 95.6, 82.5 ,199.4 ,154.3 ,97.3, 68.4, 60.9 ,112.4, 52.4,132.5 ,107.2, 114.7, 67.5, 56.4, 67.4, 93.7, 57.5 ,
92.8, 93.2, 112.7, 74.6 ,141.4, 97.6, 75.6, 100.5 ,63.6, 158.7, 132.4, 111.3, 100.9, 109.1, 78.2, 88.9, 103.8, 100.2, 74.1 ,111.18, 36.7 ,58.8 ,129.9, 112.9 ,55.1, 76.1 ,112.3)
plot(density(buffsnow,bw=5))</code></pre>
<p><img src="STA410_files/figure-html/m2plot-1.png" width="672" /></p>
<pre class="r"><code>plot(density(buffsnow,bw=4))</code></pre>
<p><img src="STA410_files/figure-html/m2plot-2.png" width="672" /></p>
<p>Estimate the parameters in the normal mixture model with m = 2:</p>
<pre class="r"><code>bins &lt;- c(66.1,105.9)
k &lt;- 2
ind &lt;- buffsnow&lt;bins[1]
sigma &lt;- sd(buffsnow[ind])
lambda &lt;- sum(ind/134)
mu &lt;- mean(buffsnow[ind])

ind &lt;- buffsnow &gt;= bins[k-1]
lambda &lt;- c(lambda, sum(ind)/134)
sigma &lt;- c(sigma, sd(buffsnow[ind]))
mu &lt;- c(mu, mean(buffsnow[ind]))
r2 &lt;- normalmixture(buffsnow, k=2, mu=mu, sigma=sigma, lambda=lambda, em.iter=200)
r2$mu</code></pre>
<pre><code>## [1] 69.67703 89.23150</code></pre>
<pre class="r"><code>r2$lambda</code></pre>
<pre><code>## [1] 0.2420873 0.7579127</code></pre>
<pre class="r"><code>r2$var</code></pre>
<pre><code>## [1] 215.7097 817.9867</code></pre>
<pre class="r"><code>r2$loglik</code></pre>
<pre><code>## [1] -1262.233</code></pre>
<pre class="r"><code>BIC2= 2*log(134) - 2*(r2$loglik)
BIC2</code></pre>
<pre><code>## [1] 2534.262</code></pre>
<p>R code for estimating the parameters in the normal mixture model with m = 3:</p>
<pre class="r"><code>bins &lt;- c(68.3,93.9,108.5)
k &lt;- 3
ind &lt;- buffsnow&lt;bins[1]
sigma &lt;- sd(buffsnow[ind])
lambda &lt;- sum(ind/134)
mu &lt;- mean(buffsnow[ind])
for (i in 2:(k-1)){
  ind &lt;- (buffsnow&lt;bins[i])&amp;(buffsnow&gt;=bins[i-1])
  lambda &lt;- c(lambda,sum(ind)/134)
  sigma &lt;-c(sigma, sd(buffsnow[ind]))
  mu &lt;- c(mu, mean(buffsnow[ind]))
}
ind &lt;- buffsnow &gt;= bins[k-1]
lambda &lt;- c(lambda, sum(ind)/134)
sigma &lt;- c(sigma, sd(buffsnow[ind]))
mu &lt;- c(mu, mean(buffsnow[ind]))
r3 &lt;- normalmixture(buffsnow, k=3, mu=mu, sigma=sigma, lambda=lambda, em.iter=200)
r3$mu</code></pre>
<pre><code>## [1] 63.84638 91.80590 92.84656</code></pre>
<pre class="r"><code>r3$lambda</code></pre>
<pre><code>## [1] 0.2735987 0.3983405 0.3280609</code></pre>
<pre class="r"><code>r3$var</code></pre>
<pre><code>## [1]  180.349  307.916 1248.298</code></pre>
<pre class="r"><code>r3$loglik</code></pre>
<pre><code>## [1] -1887.54</code></pre>
<pre class="r"><code>BIC3 = 3*log(134) - 2*(r3$loglik)
BIC3</code></pre>
<pre><code>## [1] 3789.773</code></pre>
<ol start="4" style="list-style-type: lower-alpha">
<li>The loglikehood for 2-component model is greater than that for 3-component model, which is a consequence of the EM algorithm finding a better local maximum for the 2-component model. Therefore, I prefer the model with m=2. It’s possible to use likelihood ratio tests or AIC or BIC to answer this question more precisely. BIC for model with m=2 is 2534.262; BIC for model with m=3 is 3789.773. Since BIC in the 2-component model is smaller, there is a stronger evidence that model with m=2 is a better fit.</li>
</ol>
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
